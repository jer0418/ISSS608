---
title: "Hands-on_Ex04b"
format: html
editor: visual
---

# **10  Visual Statistical Analysis**

## **10.1 Learning Outcome**

In this hands-on exercise, I have gain hands-on experience on using:

-   ggstatsplot package to create visual graphics with rich statistical information,

-   performance package to visualise model diagnostics, and

-   parameters package to visualise model parameters

## **10.2 Visual Statistical Analysis with ggstatsplot**

[**ggstatsplot**](https://indrajeetpatil.github.io/ggstatsplot/index.html) ![](https://r4va.netlify.app/chap10/img/image1.jpg){width="36"} is an extension of [**ggplot2**](https://ggplot2.tidyverse.org/) package for creating graphics with details from statistical tests included in the information-rich plots themselves.

## **10.3 Getting Started**

::: panel-tabset
## Installing and launching R packages

```{r}
#| message: true
#| warning: false
pacman::p_load(ggstatsplot, tidyverse)
```

## Importing Data

```{r}
exam <- read_csv("data/Exam_data.csv", show_col_types = FALSE)
exam
```
:::

### **10.3.3 One-sample test: *gghistostats()* method**

In the code chunk below, [*gghistostats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/gghistostats.html) is used to to build an visual of one-sample test on English scores.

```{r}
set.seed(1234)

gghistostats(
  data = exam,
  x = ENGLISH,
  type = "bayes",
  test.value = 60,
  xlab = "English scores"
)
```

Default information: - statistical details - Bayes Factor - sample sizes - distribution summary

### **10.3.4 Unpacking the Bayes Factor**

-   A Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.

-   That’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.

-   When we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as

![](https://r4va.netlify.app/chap10/img/image5.jpg)

-   The [**Schwarz criterion**](https://www.statisticshowto.com/bayesian-information-criterion/) is one of the easiest ways to calculate rough approximation of the Bayes Factor.

### **10.3.5 How to interpret Bayes Factor**

A **Bayes Factor** can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by [Lee and Wagenmakers](https://www-tandfonline-com.libproxy.smu.edu.sg/doi/pdf/10.1080/00031305.1999.10474443?needAccess=true) in 2013:

![](https://r4va.netlify.app/chap10/img/image6.jpg)

### **10.3.6 Two-sample mean test: *ggbetweenstats()***

In the code chunk below, [*ggbetweenstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) is used to build a visual for two-sample mean test of Maths scores by gender.

**H0: Mean of Female and Male Math scores are the same.**

**H1: Mean of F and M Math scores are not the same.**

```{r}
ggbetweenstats(data=exam,
               x=GENDER,
               y=MATHS,
               type='np',        #<< Non-parametric
               messages=FALSE) +
  theme(plot.background = element_rect(fill = "#f5f5f5", color = "#f5f2f5"),
        legend.background = element_rect(fill="#f5f5f5"),
        panel.background = element_rect(fill="#f5f5f5"))     
```

::: callout-tip
Based on the Mann-Whitney U test results (p=0.91p = 0.91), the median math scores for males and females are 75 and 74, respectively, with no significant difference. The 95% confidence interval includes zero, indicating little to no effect of gender on math scores. Therefore, we **fail to reject** the null hypothesis (H₀), suggesting no significant difference in math scores between males and females.
:::

### **10.3.7 Oneway ANOVA Test: *ggbetweenstats()* method**

In the code chunk below, [*ggbetweenstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbetweenstats.html) is used to build a visual for One-way ANOVA test on English score by race.

```{r}
ggbetweenstats(
  data = exam,
  x = RACE, 
  y = ENGLISH,
  type = "p",
  mean.ci = TRUE, 
  pairwise.comparisons = TRUE, 
  pairwise.display = "s",
  p.adjust.method = "fdr",
  messages = FALSE
)
```

-   **H₀ (Null Hypothesis):** The mean English scores across different racial groups are the same (no significant difference).

-   **H₁ (Alternative Hypothesis):** At least one racial group has a different mean English score (significant difference exists).

::: callout-tip
### **Conclusion**

The one-way ANOVA shows a **significant effect of race on English scores**. **Chinese and Others groups score higher**, while **Indian and Malay groups score lower**. Pairwise comparisons confirm **Chinese scores are significantly higher than Indian and Malay**. Since ppp is significant, we **reject H₀**, indicating a meaningful difference in scores among racial groups.
:::

#### 10.3.7.1 ggbetweenstats - Summary of tests

![](https://r4va.netlify.app/chap10/img/image7.jpg)

![](https://r4va.netlify.app/chap10/img/image8.jpg)

#### ![](https://r4va.netlify.app/chap10/img/image9.jpg)

### **10.3.8 Significant Test of Correlation: *ggscatterstats()***

In the code chunk below, [*ggscatterstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggscatterstats.html) is used to build a visual for Significant Test of Correlation between Maths scores and English scores.

```{r}
ggscatterstats(
  data = exam,
  x = MATHS,
  y = ENGLISH,
  marginal = FALSE,
  )
```

::: callout-tip
The scatter plot shows a **strong positive correlation** (r=0.83r = 0.83r=0.83) between Maths and English scores. The **highly significant p-value (**1.70e−831.70e-831.70e−83) confirms this relationship, with a **confidence interval of \[0.79, 0.86\]**.
:::

### **10.3.9 Significant Test of Association (Depedence) : *ggbarstats()* methods**

In the code chunk below, the Maths scores is binned into a 4-class variable by using [*cut()*](https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/cut).

```{r}
exam1 <- exam %>% 
  mutate(MATHS_bins = 
           cut(MATHS, 
               breaks = c(0,60,75,85,100))
)
```

In this code chunk below [*ggbarstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggbarstats.html) is used to build a visual for Significant Test of Association.

```{r}
ggbarstats(exam1, 
           x = MATHS_bins, 
           y = GENDER)
```

::: callout-tip
-   **No significant association** between gender and Maths score categories (χ2=1.04,p=0.79\chi\^2 = 1.04, p = 0.79χ2=1.04,p=0.79).

-   **Similar proportions** of Maths scores across genders.

-   **Maths performance appears independent of gender**.
:::

## **10.4 Visualising Models**

In this section, i will learn how to visualise model diagnostic and model parameters by using parameters package.

-   Toyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.

## **10.5 Getting Started**

::: panel-tabset
## install and load libraries

```{r}
#| message: true
#| warning: false
pacman::p_load(readxl, performance, parameters, see)
```

## Import file

```{r}
car_resale <- read_xls('data/ToyotaCorolla.xls',
                       sheet='data')
```
:::

```{r}
glimpse(car_resale)
```

### **10.6.2 Multiple Regression Model using lm()**

The code chunk below is used to calibrate a multiple linear regression model by using *lm()* of Base Stats of R.

```{r}
model <- lm(Price ~ Age_08_04 + Mfg_Year + KM + 
              Weight + Guarantee_Period, data = car_resale)
model
```

### **10.6.3 Model Diagnostic: checking for multicolinearity:**

In the code chunk, [*check_collinearity()*](https://easystats.github.io/performance/reference/check_collinearity.html) of [**performance**](https://easystats.github.io/performance/index.html) package.

```{r}
check_collinearity(model)
```

```{r}
check_c <- check_collinearity(model)
plot(check_c)
```

### **10.6.4 Model Diagnostic: checking normality assumption**

In the code chunk, [*check_normality()*](https://easystats.github.io/performance/reference/check_normality.html) of [**performance**](https://easystats.github.io/performance/index.html) package.

```{r}
model1 <- lm(Price ~ Age_08_04 + KM + 
              Weight + Guarantee_Period, data = car_resale)
```

```{r}
check_n <- check_normality(model1)
```

```{r}
plot(check_n)
```

### **10.6.5 Model Diagnostic: Check model for homogeneity of variances**

In the code chunk, [*check_heteroscedasticity()*](https://easystats.github.io/performance/reference/check_heteroscedasticity.html) of [**performance**](https://easystats.github.io/performance/index.html) package.

```{r}
check_h <- check_heteroscedasticity(model1)
```

```{r}
plot(check_h) 
```

### **10.6.6 Model Diagnostic: Complete check**

We can also perform the complete by using [*check_model()*](https://easystats.github.io/performance/reference/check_model.html).

```{r}
check_model(model1)
```

### **10.6.7 Visualising Regression Parameters: see methods**

In the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.

```{r}
plot(parameters(model1))
```

### **10.6.8 Visualising Regression Parameters: *ggcoefstats()* methods**

In the code below, [*ggcoefstats()*](https://indrajeetpatil.github.io/ggstatsplot/reference/ggcoefstats.html) of ggstatsplot package to visualise the parameters of a regression model.

```{r}
ggcoefstats(model1, 
            output = "plot")
```
